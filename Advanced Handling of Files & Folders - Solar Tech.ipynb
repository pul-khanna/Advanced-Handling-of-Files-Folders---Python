{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b89098a-1721-45d0-b8f9-ccf6c0d5a5ff",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b913ee-dc70-4146-b3e9-cd53636ebd15",
   "metadata": {},
   "source": [
    "#### The raw data is a stream of data which gets recorded by the sensors on the field and is sent over the cloud. Here the root raw data folder is called by our function 'convert' and we have used a recursive approach to loop through our folders and files while cleansing/transforing and saving them in Gen-1 data format, in the appropriate folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6186a6b0-9e9e-4af3-93da-b2773c3364ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading necessary libraries\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c47a3db-f110-46a1-97fd-99d481fa5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our working directory for our local machine\n",
    "# Note: would be different for different settings\n",
    "\n",
    "def_path = os.getcwd()\n",
    "os.chdir(def_path + '/Cleantech Assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c3c7a85-ec88-4384-8037-ab1acc71f8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pulkit/Coursera/Cleantech Assignment-20220108T092043Z-001/Cleantech Assignment'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a55e0-b11e-4a55-a20b-412c44a67811",
   "metadata": {},
   "source": [
    "#### Once in we are in the same working directory as our root folder we can run our functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d7659-6ba3-4d6b-b33f-02c585a1c56a",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d53d61-809f-4310-8daf-f16f3f5263e2",
   "metadata": {},
   "source": [
    "#### \"Function\" to find sub-directories and files structure, list and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3b565e-5329-46d1-89f4-11a141cc9658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(basepath):\n",
    "    \"\"\" Function for finding sub-directories and files list structure.\n",
    "    Parameter 'basepath' is the root folder name (name to be entered in quotes (colons) \"\"\"\n",
    "\n",
    "    with os.scandir(basepath) as entries:    \n",
    "        for entry in entries:\n",
    "            if entry.is_dir():                         \n",
    "                convert(os.path.join(basepath, entry.name))\n",
    "                              \n",
    "            elif entry.is_file():\n",
    "                file_name = entry.name\n",
    "                update_file(basepath, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825d2d9-19e0-4b45-876f-3c4ede9ca405",
   "metadata": {},
   "source": [
    "#### There are other alternate ways like using  os.walk() that is faster again but memory consuming, using Path.glob() iterator slower but not memory consuming etc. Have to try different approaches to see which performs faster (with %timeit) but usually would be a trade off bewtween speed and memory overhead and one would need see the whole data structure and knows our limitations to be able to use the method that would suit us best.\n",
    "#### Note: We can use Path.iterdir() as well but that uses listdir() under the covers, so it will be slower. However, if our directory structure is large, we'll want iterdir() instead of scandir() because scandir() wastes more limited resource than memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "611fd288-133a-4ff9-bbff-682592ce2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_file(path_list, file_name):\n",
    "    \"\"\" Function to check which transformation is to be applied to our file \"\"\"\n",
    "     \n",
    "    # extracting substation id from directory path\n",
    "    substation_id = path_list.split('/')[-1]\n",
    "    \n",
    "    if substation_id in ('Inverter_1', 'Inverter_2'):\n",
    "        inverter_file(path_list, file_name)    \n",
    "    elif substation_id == 'MFM':\n",
    "        mfm_file(path_list, file_name)\n",
    "    elif substation_id == 'WMS':\n",
    "        wms_file(path_list, file_name)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661f295-5d33-45df-be3d-7b4aebeb11a7",
   "metadata": {},
   "source": [
    "#### Differet functions to perform different transformations/cleansing operations for different sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ac7d04f-1064-4452-a88d-4ef1eb114458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverter_file(path_list, file_name):\n",
    "    \"\"\" Function to cleanse and transform file \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(path_list, file_name), sep = '\\t')\n",
    "    \n",
    "    reind_col = ['i32', 'i2', 'i3', 'i4', 'i5', 'i6', 'i7', 'i8', 'i9', 'i10', 'i11',\n",
    "                 'i12', 'i13', 'i14', 'i15', 'i16', 'i17', 'i18', 'i19', 'i20',\n",
    "                 'i21', 'i22', 'i23', 'i24', 'i25', 'i26', 'i27', 'i28', 'i29',\n",
    "                 'i30', 'i31', 'i1', 'i33', 'i34', 'i35', 'i36', 'i37', 'i38',\n",
    "                 'i39', 'i40', 'i41', 'i42', 'i43', 'i44', 'i45', 'i46', 'i47',\n",
    "                 'i48', 'i49', 'i50', 'i51', 'i52', 'i53', 'i54']\n",
    "\n",
    "    data = data.reindex(columns = reind_col)\n",
    "    \n",
    "    # swapping 'i1' with 'i32' as described in the guidelines\n",
    "    \n",
    "    final_col = ['Tstamp', 'Inverter_Id', 'Fb_Id', 'DTT', 'Device_Time', 'SES', 'Salve_Id', 'Function_Code', \n",
    "           'AC_Voltage_Line1', 'AC_Voltage_Line2', 'AC_Voltage_Line3', 'AC_Current_Line1',\n",
    "           'AC_Current_Line2', 'AC_Current_Line3', 'AC_Power', 'AC_Power_Percentage', 'AC_Frequency', \n",
    "           'Power_Factor', 'Reactive_Power', 'DC_Current', 'DC_Power', 'Inverter_Temprature',      \n",
    "           'Time_Of_Use_Today', 'Time_Of_Use_Life', 'Energy_Produced', 'KWH_Counter', 'MWH_Counter',\n",
    "           'GWH_Counter', 'DC_Voltage', 'Inverter_Status', 'Energy_Generated_Today', 'Id',\n",
    "           'Total_Energy_Generated_Till', 'Inverter_Communication_Status', 'AC_Power_2', 'AC_Power_3', \n",
    "           'AC_Frequency_2', 'AC_Frequency_3', 'DC_Voltage_2', 'DC_Power_2', 'DC_Current_2', 'Plant_Id',\n",
    "           'Inv_Status_Word', 'Grid_Conn_Status', 'AC_Current_Totoal', 'AC_Volatge_RY', 'AC_Volatge_YB',\n",
    "           'AC_Volatge_BR', 'Apparent_Power', 'Event_Flag_1', 'Event_Flag_2', 'Event_Flag_3', \n",
    "           'Event_Flag_4', 'Coolent_Temp']\n",
    "    \n",
    "    data.columns = final_col\n",
    "    \n",
    "    save_file(data, path_list, file_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "507ddb2d-49a9-4555-b336-0053cbced3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfm_file(path_list, file_name):\n",
    "    \"\"\" Function to cleanse and transform file \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(path_list, file_name), sep = '\\t')\n",
    "    \n",
    "    reind_col = ['m63', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'm8', 'm9', 'm10', 'm11',\n",
    "                 'm12', 'm13', 'm14', 'm15', 'm16', 'm17', 'm18', 'm19', 'm20',\n",
    "                 'm21', 'm22', 'm23', 'm24', 'm25', 'm26', 'm27', 'm28', 'm29',\n",
    "                 'm30', 'm31', 'm32', 'm33', 'm34', 'm35', 'm36', 'm37', 'm38',\n",
    "                 'm39', 'm40', 'm41', 'm42', 'm43', 'm44', 'm45', 'm46', 'm47',\n",
    "                 'm48', 'm49', 'm50', 'm51', 'm52', 'm53', 'm54', 'm55', 'm56',\n",
    "                 'm57', 'm58', 'm59', 'm60', 'm61', 'm62', 'm1', 'm64', 'm65',\n",
    "                 'm66', 'm67']\n",
    "\n",
    "    data = data.reindex(columns = reind_col)    \n",
    "        \n",
    "    # swapping 'm1' with 'm63' as described in the guidelines\n",
    "    \n",
    "    final_col = ['Tstamp', 'm2', 'm3', 'm4', 'm5', 'm6', 'm7', 'Voltage_R_Phase', 'Voltage_Y_Phase', \n",
    "                 'Voltage_B_Phase', 'Average_Voltage', 'Voltage_R_Y', 'Voltage_Y_B', 'Voltage_B_R',\n",
    "                 'Line_To_Line_Voltage_Average', 'Current_R', 'Current_Y', 'Current_B', 'Current_N',\n",
    "                 'Average_Current', 'Frequency_R', 'Frequency_Y', 'Frequency_B', 'Average_Frequency',\n",
    "                 'Power_Factor_R', 'Power_Factor_Y', 'Power_Factor_B', 'Average_Power_Factor', \n",
    "                 'Active_Power_R', 'Active_Power_Y', 'Active_Power_B', 'Total_Power', 'Reactive_Power_R',\n",
    "                 'Reactive_Power_Y', 'Reactive_Power_B', 'Total_Reactive_Power', 'Total_Apparent_Power',\n",
    "                 'Active_Energy', 'Reactive_Energy', 'Apparent_Power_R', 'Apparent_Power_Y',\n",
    "                 'Apparent_Power_B', 'Reactive_Energy2', 'Maximum_Active_Power', 'Minimum_Active_Power',\n",
    "                 'Maximum_Reactive_Power', 'Minimum_Reactive_Power', 'Maximum_Apparent_Power', \n",
    "                 'Wh_Received', 'VAh_Received', 'VARh_Inductive_Received', 'VARh_Capacitive_Received',\n",
    "                 'Energy_Export1', 'VAh_Delivered', 'VARh_Ind_Delivered', 'VARh_Cap_Delivered', 'THD',\n",
    "                 'Active_Total_Import', 'Active_Total_Export', 'Apparent_Import', 'Aparent_Export',\n",
    "                 'Energy_Today', 'm1', 'Energy_Import', 'Energy_Export', 'm66', 'Total_KW_Avg']\n",
    "    \n",
    "    data.columns = final_col\n",
    "    \n",
    "    save_file(data, path_list, file_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "908ddcf6-7986-4588-ae85-c735d7b0c91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wms_file(path_list, file_name):\n",
    "    \"\"\" Function to cleanse and transform file \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(os.path.join(path_list, file_name), sep = '\\t')\n",
    "    \n",
    "    reind_col = ['w23', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11',\n",
    "                 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'w19', 'w20',\n",
    "                 'w21', 'w22', 'w1', 'w24', 'w25', 'w26', 'w27', 'w28', 'w29',\n",
    "                 'w30', 'w31', 'w32', 'w33', 'w34', 'w35']\n",
    "\n",
    "    data = data.reindex(columns = reind_col)    \n",
    "        \n",
    "    # swapping 'w1' with 'w23' as described in the guidelines\n",
    "\n",
    "    final_col = ['Tstamp', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'Humidity_Min', 'Module_Temp1', \n",
    "                 'Wind_Direction', 'Wind_Speed', 'Ambient_Temp', 'Module_Temp2_Actual', 'Humidity_Max', \n",
    "                 'Humidity_Actual', 'Ambient_Temp_Min', 'Ambient_Temp_Max', 'Ambient_Temp_Avg',\n",
    "                 'Global_Irradiation_Min', 'Irradiation_Tilt1_Actual', 'Irradiation_Tilt2_Actual', \n",
    "                 'w1', 'Global_Irradiation_Max', 'Global_Irradiation_Avg', 'Wind_Speed_Min', \n",
    "                 'Wind_Speed_Max', 'Humidity_Avg', 'Wind_Direction_Min', 'Wind_Direction_Max',\n",
    "                 'Wind_Speed_Avg', 'Global_Irradiation_Actual', 'w33', 'Rain', 'Room_Temperature']\n",
    "    \n",
    "    data.columns = final_col\n",
    "    \n",
    "    save_file(data, path_list, file_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351fc4f-023c-4bcf-88de-c2944a7ec306",
   "metadata": {},
   "source": [
    "#### Note: Using set_index first and then reset_index is faster method to set our 'Tstamp' as first column, however it will shift 'i1' to the second column and all following rows will shift by 1 position. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab068805-c8da-476a-aaa2-ad3f0f5276ad",
   "metadata": {},
   "source": [
    "#### Function to extract 'year' and 'month' and save the cleansed file in the appropriate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c311da0-d080-46b5-b92b-5145aac90e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(data, path_list, file_name):    \n",
    "    \"\"\" Extracting 'year' and 'month' from our data to use it later for naming the sub-folders as decribed \n",
    "    in the guidelines  \"\"\"\n",
    "    \n",
    "    # extracting station id and substation id name from folder path\n",
    "    station_id = path_list.split('/')[1]\n",
    "    substation_id = path_list.split('/')[-1]\n",
    "    \n",
    "    get_date = pd.to_datetime(data.loc[0,'Tstamp'], errors = 'coerce')\n",
    "    year = str(get_date.year)\n",
    "    month = str(get_date.month)    \n",
    "    \n",
    "    \"\"\" Saving our file as described in the appropriate folders \"\"\"\n",
    "    \n",
    "    filepath = f\"{r'Gen1'}/{station_id}/{year}/{year}-{month}/{substation_id}/\"\n",
    "    Path(filepath).mkdir(parents = True, exist_ok = True)\n",
    "    data.to_csv(os.path.join(filepath,file_name), index = None, sep = '\\t', mode = 'w')\n",
    "    \n",
    "    # Alternative way to write code in above line as below:- \n",
    "    # data.to_csv(filepath + file_name, index = None, sep = '\\t', mode = 'w')\n",
    "    # To avoid ambiguity and to allow portability we prefer the first code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2887fe9-f39f-476e-bd2b-18be3e93c817",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c0bd5-5424-45e6-89fc-55e2a43099c4",
   "metadata": {},
   "source": [
    "#### Call the function with root folder name to cleanse/transform all the files and save them in appropriate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d4803f1-5054-471c-be26-37126dc56e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert('raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc066c-7ec8-4f0c-ad60-dfdb7a320332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
